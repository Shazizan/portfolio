{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpA3ZBlZ01kmFR12c4uQci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shazizan/portfolio/blob/master/etl_vault_lambda_stock_price_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Method 2 of Using Lambda Fx**"
      ],
      "metadata": {
        "id": "kESMz42V908x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D6TYXrc39so",
        "outputId": "544c99c4-4cda-48dd-92f0-1613fa7adbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üöÄ Starting ETL Pipeline: GitHub CSV ‚Üí JSON Transfer\n",
            "============================================================\n",
            "\n",
            "üì• Extracting data from: Shazizan/data/stock_price.csv\n",
            "‚úÖ Extraction successful!\n",
            "\n",
            "üîÑ Transforming CSV to JSON...\n",
            "‚úÖ Transformation complete! Converted 24 rows\n",
            "\n",
            "üì§ Loading data to: Shazizan/pipeline-vault/stock_price.json\n",
            "üìù Creating new file...\n",
            "‚úÖ Load successful!\n",
            "\n",
            "============================================================\n",
            "üéâ ETL Pipeline completed successfully!\n",
            "============================================================\n",
            "\n",
            "üìä File uploaded to: https://github.com/Shazizan/pipeline-vault/blob/main/stock_price.json\n"
          ]
        }
      ],
      "source": [
        "# GitHub ETL Pipeline: CSV to JSON Transfer Between Repositories\n",
        "# This script demonstrates Extract, Transform, Load (ETL) process using lambda functions\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: IMPORT REQUIRED LIBRARIES\n",
        "# ============================================================================\n",
        "\n",
        "import requests  # Used to make HTTP requests to GitHub API\n",
        "import json  # Used to work with JSON data format\n",
        "import csv  # Used to parse CSV files\n",
        "import base64  # GitHub API requires file content to be base64 encoded\n",
        "from io import StringIO  # Allows us to treat strings as file objects\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: CONFIGURATION - Replace with your actual values\n",
        "# ============================================================================\n",
        "\n",
        "# GitHub Personal Access Token - needed for authentication\n",
        "# Generate at: https://github.com/settings/tokens (needs 'repo' scope)\n",
        "GITHUB_TOKEN = \"PLACE_YOUR_TOKEN_HERE\"\n",
        "\n",
        "# Source Repository Configuration (where CSV file is located)\n",
        "SOURCE_OWNER = \"Shazizan\"  # GitHub username/org of source repo\n",
        "SOURCE_REPO = \"data\"  # Name of source repository\n",
        "SOURCE_FILE_PATH = \"stock_price.csv\"  # Path to CSV file in source repo\n",
        "\n",
        "# Destination Repository Configuration (where JSON will be uploaded)\n",
        "DEST_OWNER = \"Shazizan\"  # GitHub username/org of destination repo\n",
        "DEST_REPO = \"pipeline-vault\"  # Name of destination repository\n",
        "DEST_FILE_PATH = \"stock_price.json\"  # Path where JSON will be saved\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: LAMBDA FUNCTIONS FOR ETL PROCESS\n",
        "# ============================================================================\n",
        "\n",
        "# Lambda function to create GitHub API headers\n",
        "# Purpose: Adds authentication and specifies we're sending JSON\n",
        "create_headers = lambda token: {\n",
        "    \"Authorization\": f\"Bearer {token}\",  # Authenticates our request\n",
        "    \"Accept\": \"application/vnd.github.v3+json\",  # Specifies GitHub API version\n",
        "    \"Content-Type\": \"application/json\"  # Tells GitHub we're sending JSON\n",
        "}\n",
        "\n",
        "# Lambda function to construct GitHub API URL\n",
        "# Purpose: Builds the correct URL to access files in a repository\n",
        "build_url = lambda owner, repo, path: f\"https://api.github.com/repos/{owner}/{repo}/contents/{path}\"\n",
        "\n",
        "# Lambda function to decode base64 content\n",
        "# Purpose: GitHub returns file content in base64, this decodes it to text\n",
        "decode_content = lambda content: base64.b64decode(content).decode('utf-8')\n",
        "\n",
        "# Lambda function to encode content to base64\n",
        "# Purpose: GitHub requires file uploads to be base64 encoded\n",
        "encode_content = lambda content: base64.b64encode(content.encode('utf-8')).decode('utf-8')\n",
        "\n",
        "# Lambda function to parse CSV to list of dictionaries\n",
        "# Purpose: Converts CSV rows into Python dictionaries for easy manipulation\n",
        "parse_csv = lambda csv_text: list(csv.DictReader(StringIO(csv_text)))\n",
        "\n",
        "# Lambda function to convert list to JSON string\n",
        "# Purpose: Transforms Python data structure into formatted JSON\n",
        "to_json = lambda data: json.dumps(data, indent=2)  # indent=2 makes it readable\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: EXTRACT FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def extract_csv_from_github(owner, repo, file_path, token):\n",
        "    \"\"\"\n",
        "    Extract CSV data from GitHub repository\n",
        "\n",
        "    Args:\n",
        "        owner: GitHub username or organization\n",
        "        repo: Repository name\n",
        "        file_path: Path to file within repository\n",
        "        token: GitHub personal access token\n",
        "\n",
        "    Returns:\n",
        "        String content of the CSV file\n",
        "    \"\"\"\n",
        "\n",
        "    # Build the API URL for the file\n",
        "    url = build_url(owner, repo, file_path)\n",
        "\n",
        "    # Create authentication headers\n",
        "    headers = create_headers(token)\n",
        "\n",
        "    # Make GET request to GitHub API\n",
        "    print(f\"üì• Extracting data from: {owner}/{repo}/{file_path}\")\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Check if request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the JSON response\n",
        "        file_data = response.json()\n",
        "\n",
        "        # Decode the base64 content to get actual CSV text\n",
        "        csv_content = decode_content(file_data['content'])\n",
        "\n",
        "        print(\"‚úÖ Extraction successful!\")\n",
        "        return csv_content\n",
        "    else:\n",
        "        # If request failed, raise an error with details\n",
        "        raise Exception(f\"‚ùå Failed to extract: {response.status_code} - {response.text}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: TRANSFORM FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def transform_csv_to_json(csv_content):\n",
        "    \"\"\"\n",
        "    Transform CSV content to JSON format\n",
        "\n",
        "    Args:\n",
        "        csv_content: String content of CSV file\n",
        "\n",
        "    Returns:\n",
        "        JSON string representation of the data\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üîÑ Transforming CSV to JSON...\")\n",
        "\n",
        "    # Parse CSV text into list of dictionaries using lambda function\n",
        "    data = parse_csv(csv_content)\n",
        "\n",
        "    # Convert to JSON string using lambda function\n",
        "    json_content = to_json(data)\n",
        "\n",
        "    print(f\"‚úÖ Transformation complete! Converted {len(data)} rows\")\n",
        "    return json_content\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: LOAD FUNCTION\n",
        "# ============================================================================\n",
        "\n",
        "def load_json_to_github(owner, repo, file_path, json_content, token, commit_message=\"ETL: Upload transformed data\"):\n",
        "    \"\"\"\n",
        "    Load JSON data to GitHub repository\n",
        "\n",
        "    Args:\n",
        "        owner: GitHub username or organization\n",
        "        repo: Repository name\n",
        "        file_path: Path where file should be saved\n",
        "        json_content: JSON string to upload\n",
        "        token: GitHub personal access token\n",
        "        commit_message: Git commit message\n",
        "\n",
        "    Returns:\n",
        "        Response from GitHub API\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"üì§ Loading data to: {owner}/{repo}/{file_path}\")\n",
        "\n",
        "    # Build the API URL for destination\n",
        "    url = build_url(owner, repo, file_path)\n",
        "\n",
        "    # Create authentication headers\n",
        "    headers = create_headers(token)\n",
        "\n",
        "    # First, check if file already exists (to get SHA for update)\n",
        "    check_response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Prepare the payload for GitHub API\n",
        "    payload = {\n",
        "        \"message\": commit_message,  # Git commit message\n",
        "        \"content\": encode_content(json_content),  # Base64 encoded content\n",
        "        \"branch\": \"main\"  # Target branch (change if needed)\n",
        "    }\n",
        "\n",
        "    # If file exists, we need to include its SHA for update\n",
        "    if check_response.status_code == 200:\n",
        "        payload[\"sha\"] = check_response.json()['sha']\n",
        "        print(\"üìù File exists, updating...\")\n",
        "    else:\n",
        "        print(\"üìù Creating new file...\")\n",
        "\n",
        "    # Make PUT request to create/update file\n",
        "    response = requests.put(url, headers=headers, json=payload)\n",
        "\n",
        "    # Check if upload was successful\n",
        "    if response.status_code in [200, 201]:\n",
        "        print(\"‚úÖ Load successful!\")\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(f\"‚ùå Failed to load: {response.status_code} - {response.text}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: MAIN ETL PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "def run_etl_pipeline():\n",
        "    \"\"\"\n",
        "    Execute the complete ETL pipeline\n",
        "\n",
        "    This function orchestrates the Extract, Transform, Load process\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üöÄ Starting ETL Pipeline: GitHub CSV ‚Üí JSON Transfer\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    try:\n",
        "        # EXTRACT: Get CSV data from source repository\n",
        "        csv_data = extract_csv_from_github(\n",
        "            owner=SOURCE_OWNER,\n",
        "            repo=SOURCE_REPO,\n",
        "            file_path=SOURCE_FILE_PATH,\n",
        "            token=GITHUB_TOKEN\n",
        "        )\n",
        "\n",
        "        print()  # Empty line for readability\n",
        "\n",
        "        # TRANSFORM: Convert CSV to JSON\n",
        "        json_data = transform_csv_to_json(csv_data)\n",
        "\n",
        "        print()  # Empty line for readability\n",
        "\n",
        "        # LOAD: Upload JSON to destination repository\n",
        "        result = load_json_to_github(\n",
        "            owner=DEST_OWNER,\n",
        "            repo=DEST_REPO,\n",
        "            file_path=DEST_FILE_PATH,\n",
        "            json_content=json_data,\n",
        "            token=GITHUB_TOKEN,\n",
        "            commit_message=\"ETL Pipeline: Automated CSV to JSON conversion\"\n",
        "        )\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üéâ ETL Pipeline completed successfully!\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"\\nüìä File uploaded to: {result['content']['html_url']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"üí• ETL Pipeline failed: {str(e)}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: EXECUTE THE PIPELINE\n",
        "# ============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run the ETL pipeline\n",
        "    run_etl_pipeline()\n",
        "\n",
        "# ============================================================================\n",
        "# ADDITIONAL HELPER FUNCTIONS (Optional but useful)\n",
        "# ============================================================================\n",
        "\n",
        "# Lambda to validate GitHub token format\n",
        "validate_token = lambda token: token.startswith(('ghp_', 'github_pat_'))\n",
        "\n",
        "# Lambda to get file extension\n",
        "get_extension = lambda filename: filename.split('.')[-1]\n",
        "\n",
        "# Lambda to create timestamp for unique filenames\n",
        "from datetime import datetime\n",
        "create_timestamp = lambda: datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Example: Create unique output filename with timestamp\n",
        "# unique_filename = lambda base: f\"{base}_{create_timestamp()}.json\""
      ]
    }
  ]
}